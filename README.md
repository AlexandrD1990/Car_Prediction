Домашнее задание №1

**EDA и визуализация**

Отобразил 30 случайных строк тренировочного датасета.

Отобразил первые 5 и последние 5 объектов тестового датасета.

Сделаны Выводы использования случайных/верхних/нижних строк.

Вывод: Можно сделать вывод о количестве строк и столбцов, увидеть значения для последующей обработки например в столбцах mileage, engine, max_power, torque. нельзя точно сказать сколько пропусков , дублирований строк и о диапазоне значений.

Выявил пропуски. Записал и вывел названия колонок, для которых есть пропущенные значения. mileage 202 engine 202 max_power 196 torque 203 seats 202

Вывел явные дубликаты данных.

Вывод: Достаточно метода duplicated если мы ищем полностью дублирующие строки и данные введены с одинаковым регистром и количеством пробелов, а если есть не совпадение хоть по одному столбцу, то не будет считаться дубликатом, придется искать решение.

Построение дашборда, используя ydata-profilling

Заполнил пропуски в столбцах медианами для обоих наборов данных.

Вывел есть ли в трейне объекты с одинаковым признаковым описанием исключив целевую переменную.

Вывод: 1799 объектов с одинаковым признаковым описанием

Удалил повторяющиеся строки.

Обновил индексы строк.

Убрал единицы измерения для признаков mileage, engine, max_power привел тип данных к float.

Удали столбец torque.

Осуществил приведение столбцов engnine и seats к необходимому типу int.

Посчитал основные статистики по числовым столбцам для трейна и теста.

Посчитайте основные статистики по категориальным столбцам для трейна и теста.

Сделал вывод.

Вывод: max значение в df_train в selling_price и km_driven на много выше нормального распределения, эти значения могут повлиять на предсказание модели

Визуализация данных.

Визуализировал попарные распределения числовых признаков для train и test

Предположил на основе распределений связь признаков с целевой переменной.

Выдвинул гипотезу о корреляциях признаков.

Связь признаков с целевой переменной:

Зависимость selling_price от yers линейная положительная чем новее тем дороже, km_driven линейная отрицательная чем больше пробег тем дешевле и max_power не линейная положительная чем мощнее тем дороже 

Гипотеза: Зависимость engine max_power чем больше объем двигателя тем мощнее. year km_driven чем старее тем больше пробег

Получил значения коэффициента корреляции Пирсона для тренировочного набора данных.

По полученным корреляциям построил тепловую карту heatmap.

Сделал вывод.

Признаки max_power и year наименее скоррелированы между собой

Между engine и seats 0.84

selling_price и max_power 0.82

max_power и engine 0.82

довольно сильная положительная линейная зависимость

Сделал дополнительные визуализации.

Значения max целевой переменной selling_price и признака km_driven , выходят за нормальное распределение поэтому постоим boxplot

Цена на некоторые автомобили значительно выше среднего

Пробег некоторых автомобилей сильно выше среднего

**Модель только на вещественных признаках**

Разбиение данных на тренировочный и тестовый наборы.

В переменные y_train и y_test записал значения целевых переменных.

Обучил классическую линейную регрессию с дефолтными параметрами. Посчтитал  R2  и  MSE  для трейна и для теста.

Сделал вывод о метриках.

Вывод: mse достаточно большое число, т.к. высокий диапазон значений selling_price выходящие за нормальное распределение, соответственно предсказание может сильно отличаться. 

Например отличие от настоящей цены на 483010

R2 чуть выше среднего , снова влияние цен которые выходять за нормальное распределение. модель на тренировочных данных предсказывает лучше чем на тестовых.

Стандартизировал значения в тренировочных и тестовых данных. Показатели метрики практически не изменились.

Интерпретировал важность признаков в модели.

Обучил Lasso регрессию на тренировочном наборе данных с нормализованными признаками. mse на test при a=0.01 такая же как и до регуляризации, при увеличении a mse растёт

Перебором по сетке подобрал оптимальные параметры для Lasso-регрессии.

Сделал вывод.

Вывод: грид-сёрчу пришлось обучать 50 моделей, коэффициент регуляризации у лучшей из перебранных моделей = 0.01

Перебором по сетке подобрал оптимальные параметры для ElasticNet регрессии.

Вывод: грид-сёрчу пришлось обучать 150 моделей, alpha=0.01, l1_ratio=0.1 соответствуют лучшей из перебранных моделей. Сильно улучшить предсказание не удалось.  

Удалил столбец name.

Закодировал категориальные фичи и seats методом OneHot-кодирования.

Переберал параметр регуляризации alpha для гребневой ridge регрессии с помощью класса GridSearchCV 

Вывод: в целом качество прогноза изменилось очень не значительно.

Реализовал метрику business_metric

Посчитал метрику для всех обученных моделей и определил, какая лучше всего решает задачу бизнеса 

Вывод: ElasticNet на 0.1% предсказывает лучше остальных моделей